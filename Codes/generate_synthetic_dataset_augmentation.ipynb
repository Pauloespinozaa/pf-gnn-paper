{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e6faa6",
   "metadata": {},
   "source": [
    "# Generate Dataset\n",
    "\n",
    "The dataset generation phase was designed to provide a diverse and representative set of power flow scenarios that capture both nominal operating conditions and variations arising from topological changes. To this end, we employed the IEEE test network as the baseline model and systematically simulated a wide range of load and generation profiles. Each observation in the dataset consists of nodal features, such as active power \n",
    "(\n",
    "ğ‘ƒ\n",
    ")\n",
    "(P), reactive power \n",
    "(\n",
    "ğ‘„\n",
    ")\n",
    "(Q), voltage magnitude \n",
    "(\n",
    "ğ‘‰\n",
    ")\n",
    "(V), and voltage angle \n",
    "(\n",
    "ğœƒ\n",
    ")\n",
    "(Î¸), along with node type information (Slack, PV, PQ). Additionally, branch-related parameters, including line conductance \n",
    "(\n",
    "ğº\n",
    ")\n",
    "(G), susceptance \n",
    "(\n",
    "ğµ\n",
    ")\n",
    "(B), and line type, were incorporated to preserve the electrical properties of the network.\n",
    "\n",
    "To enhance the generalization capability of the proposed models, topological perturbations were introduced through controlled modifications in the adjacency matrix. These perturbations emulate realistic contingencies such as line disconnections and variations in connectivity, thereby creating multiple graph representations for the same physical system. For each perturbed state, we ensured that the resulting dataset retained electrical feasibility by running load flow calculations and validating that operating constraints were respected.\n",
    "\n",
    "The final dataset comprises both unperturbed and perturbed network configurations, enabling the learning process to account for a wide spectrum of operating conditions. This approach not only improves robustness against unseen topological variations but also better reflects the stochastic and dynamic nature of modern power distribution systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cb617",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9a4e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61.2\n"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks as nw\n",
    "import pandapower.topology as top\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy, random\n",
    "import numba\n",
    "print(numba.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63706f80",
   "metadata": {},
   "source": [
    "## Test Case 14 Buses - Panda Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f570f32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generadas: 5000/500000\n",
      "âœ… Datasets generados y divididos correctamente:\n",
      "  Train â†’ 21000 muestras\n",
      "  Val   â†’ 4500 muestras\n",
      "  Test  â†’ 4500 muestras\n"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks as nw\n",
    "import pandapower.topology as top\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy, random\n",
    "\n",
    "# ConfiguraciÃ³n inicial\n",
    "net_base = nw.case14()\n",
    "orig_p, orig_q = net_base.load.p_mw.copy(), net_base.load.q_mvar.copy()\n",
    "VAR_RANGE = 0.4\n",
    "\n",
    "# Funciones necesarias\n",
    "def is_connected(net):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return nx.is_connected(G)\n",
    "\n",
    "def eligible_nodes(net, min_degree):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return [node for node, deg in G.degree if deg > min_degree]\n",
    "\n",
    "def lines_connected_to_node(net, node):\n",
    "    return net.line.index[(net.line.from_bus == node) | (net.line.to_bus == node)].tolist()\n",
    "\n",
    "def generate_sample(net, augment=True, max_attempts=20):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts and augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        k = random.choice([1, 2, 3])\n",
    "        eligible = eligible_nodes(net_trial, k)\n",
    "\n",
    "        if not eligible:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        node_selected = random.choice(eligible)\n",
    "        candidate_lines = lines_connected_to_node(net_trial, node_selected)\n",
    "\n",
    "        if len(candidate_lines) < k:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        lines_off = random.sample(candidate_lines, k)\n",
    "        net_trial.line.loc[lines_off, 'in_service'] = False\n",
    "\n",
    "        if is_connected(net_trial):\n",
    "            try:\n",
    "                pp.runpp(net_trial)\n",
    "                return net_trial, lines_off\n",
    "            except pp.LoadflowNotConverged:\n",
    "                pass\n",
    "        attempts += 1\n",
    "\n",
    "    if not augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        pp.runpp(net_trial)\n",
    "        return net_trial, []\n",
    "\n",
    "    return None, []\n",
    "\n",
    "# Generador de registros\n",
    "def build_records(net, n_samples, augment):\n",
    "    records = []\n",
    "    sample_count = 0\n",
    "    while sample_count < n_samples:\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        net_copy.load['p_mw'] = orig_p * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_p)))\n",
    "        net_copy.load['q_mvar'] = orig_q * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_q)))\n",
    "\n",
    "        net_var, lines_off = generate_sample(net_copy, augment)\n",
    "\n",
    "        if net_var is None:\n",
    "            continue\n",
    "\n",
    "        Z_vector = np.ones(net.bus.shape[0], dtype=int)\n",
    "        for idx in lines_off:\n",
    "            Z_vector[net_var.line.at[idx, 'from_bus']] = 0\n",
    "            Z_vector[net_var.line.at[idx, 'to_bus']] = 0\n",
    "\n",
    "        rec = {\n",
    "            \"Sample\": f\"Data {sample_count+1}\",\n",
    "            \"Label\": \"FAIL\" if lines_off else \"OK\",\n",
    "            \"Edges_Out_List\": [f\"{net.line.at[idx, 'from_bus']}-{net.line.at[idx, 'to_bus']}\" for idx in lines_off],\n",
    "            \"Branch_Edge_Index\": [[], []],\n",
    "            \"Branch_G\": [], \"Branch_B\": [], \"Branch_Type\": [],\n",
    "            \"Z_vector\": Z_vector.tolist()\n",
    "        }\n",
    "\n",
    "        for _, ln in net_var.line[net_var.line.in_service].iterrows():\n",
    "            u, v = int(ln.from_bus), int(ln.to_bus)\n",
    "            z = complex(ln.r_ohm_per_km * ln.length_km, ln.x_ohm_per_km * ln.length_km)\n",
    "            y = 1/z\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(0)\n",
    "\n",
    "        for _, tr in net_var.trafo[net_var.trafo.in_service].iterrows():\n",
    "            u, v = int(tr.hv_bus), int(tr.lv_bus)\n",
    "            r_pu = tr.vkr_percent / 100.0\n",
    "            vk = tr.vk_percent / 100.0\n",
    "            x_pu = np.sqrt(max(vk*vk - r_pu*r_pu, 0.0))\n",
    "            y = 1 / complex(r_pu, x_pu)\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(1)\n",
    "\n",
    "        for bus in net.bus.index:\n",
    "            p_load = net_var.res_load.p_mw[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            q_load = net_var.res_load.q_mvar[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            ntype = \"PQ\" if bus in net_var.load.bus.values else (\"Slack\" if net_var.bus.at[bus, 'type']==3 else \"PV\")\n",
    "            rec[f\"P_{bus} ({ntype})\"], rec[f\"Q_{bus} ({ntype})\"] = p_load, q_load\n",
    "            rec[f\"V_{bus}\"] = net_var.res_bus.vm_pu.at[bus]\n",
    "            rec[f\"d_{bus}\"] = net_var.res_bus.va_degree.at[bus]\n",
    "            rec[f\"Z_{bus}\"] = int(Z_vector[bus])\n",
    "\n",
    "        records.append(rec)\n",
    "        sample_count += 1\n",
    "        print(f\"Generadas: {sample_count}/{n_samples}\", end='\\r')\n",
    "\n",
    "    return records\n",
    "\n",
    "# â”€â”€â”€ GeneraciÃ³n y mezcla total â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_records = (\n",
    "    build_records(net_base, 10000, augment=False) +\n",
    "    build_records(net_base, 5000, augment=True) +\n",
    "    build_records(net_base, 10000, augment=True) +\n",
    "    build_records(net_base, 5000, augment=False)\n",
    ")\n",
    "\n",
    "df_all = pd.DataFrame(all_records).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# â”€â”€â”€ Split 70% train / 15% val / 15% test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_total = len(df_all)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val   = int(0.15 * n_total)\n",
    "n_test  = n_total - n_train - n_val\n",
    "\n",
    "train_df = df_all.iloc[:n_train]\n",
    "val_df   = df_all.iloc[n_train:n_train + n_val]\n",
    "test_df  = df_all.iloc[n_train + n_val:]\n",
    "\n",
    "# â”€â”€â”€ Guardar resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "train_df.to_excel(\"train_data_final_14_buses.xlsx\", index=False)\n",
    "val_df.to_excel(\"val_data_final_14_buses.xlsx\", index=False)\n",
    "test_df.to_excel(\"test_data_final_14_buses.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Datasets generados y divididos correctamente:\")\n",
    "print(f\"  Train â†’ {len(train_df)} muestras\")\n",
    "print(f\"  Val   â†’ {len(val_df)} muestras\")\n",
    "print(f\"  Test  â†’ {len(test_df)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702aa6c1",
   "metadata": {},
   "source": [
    "## Test Case 30 Buses - Panda Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88ba15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generadas: 5000/500000\n",
      "âœ… Datasets generados y divididos correctamente:\n",
      "  Train â†’ 21000 muestras\n",
      "  Val   â†’ 4500 muestras\n",
      "  Test  â†’ 4500 muestras\n"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks as nw\n",
    "import pandapower.topology as top\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy, random\n",
    "\n",
    "# ConfiguraciÃ³n inicial\n",
    "net_base = nw.case30()\n",
    "orig_p, orig_q = net_base.load.p_mw.copy(), net_base.load.q_mvar.copy()\n",
    "VAR_RANGE = 0.4\n",
    "\n",
    "# Funciones necesarias\n",
    "def is_connected(net):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return nx.is_connected(G)\n",
    "\n",
    "def eligible_nodes(net, min_degree):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return [node for node, deg in G.degree if deg > min_degree]\n",
    "\n",
    "def lines_connected_to_node(net, node):\n",
    "    return net.line.index[(net.line.from_bus == node) | (net.line.to_bus == node)].tolist()\n",
    "\n",
    "def generate_sample(net, augment=True, max_attempts=20):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts and augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        k = random.choice([1, 2, 3])\n",
    "        eligible = eligible_nodes(net_trial, k)\n",
    "\n",
    "        if not eligible:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        node_selected = random.choice(eligible)\n",
    "        candidate_lines = lines_connected_to_node(net_trial, node_selected)\n",
    "\n",
    "        if len(candidate_lines) < k:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        lines_off = random.sample(candidate_lines, k)\n",
    "        net_trial.line.loc[lines_off, 'in_service'] = False\n",
    "\n",
    "        if is_connected(net_trial):\n",
    "            try:\n",
    "                pp.runpp(net_trial)\n",
    "                return net_trial, lines_off\n",
    "            except pp.LoadflowNotConverged:\n",
    "                pass\n",
    "        attempts += 1\n",
    "\n",
    "    if not augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        pp.runpp(net_trial)\n",
    "        return net_trial, []\n",
    "\n",
    "    return None, []\n",
    "\n",
    "# Generador de registros\n",
    "def build_records(net, n_samples, augment):\n",
    "    records = []\n",
    "    sample_count = 0\n",
    "    while sample_count < n_samples:\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        net_copy.load['p_mw'] = orig_p * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_p)))\n",
    "        net_copy.load['q_mvar'] = orig_q * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_q)))\n",
    "\n",
    "        net_var, lines_off = generate_sample(net_copy, augment)\n",
    "\n",
    "        if net_var is None:\n",
    "            continue\n",
    "\n",
    "        Z_vector = np.ones(net.bus.shape[0], dtype=int)\n",
    "        for idx in lines_off:\n",
    "            Z_vector[net_var.line.at[idx, 'from_bus']] = 0\n",
    "            Z_vector[net_var.line.at[idx, 'to_bus']] = 0\n",
    "\n",
    "        rec = {\n",
    "            \"Sample\": f\"Data {sample_count+1}\",\n",
    "            \"Label\": \"FAIL\" if lines_off else \"OK\",\n",
    "            \"Edges_Out_List\": [f\"{net.line.at[idx, 'from_bus']}-{net.line.at[idx, 'to_bus']}\" for idx in lines_off],\n",
    "            \"Branch_Edge_Index\": [[], []],\n",
    "            \"Branch_G\": [], \"Branch_B\": [], \"Branch_Type\": [],\n",
    "            \"Z_vector\": Z_vector.tolist()\n",
    "        }\n",
    "\n",
    "        for _, ln in net_var.line[net_var.line.in_service].iterrows():\n",
    "            u, v = int(ln.from_bus), int(ln.to_bus)\n",
    "            z = complex(ln.r_ohm_per_km * ln.length_km, ln.x_ohm_per_km * ln.length_km)\n",
    "            y = 1/z\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(0)\n",
    "\n",
    "        for _, tr in net_var.trafo[net_var.trafo.in_service].iterrows():\n",
    "            u, v = int(tr.hv_bus), int(tr.lv_bus)\n",
    "            r_pu = tr.vkr_percent / 100.0\n",
    "            vk = tr.vk_percent / 100.0\n",
    "            x_pu = np.sqrt(max(vk*vk - r_pu*r_pu, 0.0))\n",
    "            y = 1 / complex(r_pu, x_pu)\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(1)\n",
    "\n",
    "        for bus in net.bus.index:\n",
    "            p_load = net_var.res_load.p_mw[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            q_load = net_var.res_load.q_mvar[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            ntype = \"PQ\" if bus in net_var.load.bus.values else (\"Slack\" if net_var.bus.at[bus, 'type']==3 else \"PV\")\n",
    "            rec[f\"P_{bus} ({ntype})\"], rec[f\"Q_{bus} ({ntype})\"] = p_load, q_load\n",
    "            rec[f\"V_{bus}\"] = net_var.res_bus.vm_pu.at[bus]\n",
    "            rec[f\"d_{bus}\"] = net_var.res_bus.va_degree.at[bus]\n",
    "            rec[f\"Z_{bus}\"] = int(Z_vector[bus])\n",
    "\n",
    "        records.append(rec)\n",
    "        sample_count += 1\n",
    "        print(f\"Generadas: {sample_count}/{n_samples}\", end='\\r')\n",
    "\n",
    "    return records\n",
    "\n",
    "# â”€â”€â”€ GeneraciÃ³n y mezcla total â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_records = (\n",
    "    build_records(net_base, 10000, augment=False) +\n",
    "    build_records(net_base, 5000, augment=True) +\n",
    "    build_records(net_base, 10000, augment=True) +\n",
    "    build_records(net_base, 5000, augment=False)\n",
    ")\n",
    "\n",
    "df_all = pd.DataFrame(all_records).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# â”€â”€â”€ Split 70% train / 15% val / 15% test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_total = len(df_all)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val   = int(0.15 * n_total)\n",
    "n_test  = n_total - n_train - n_val\n",
    "\n",
    "train_df = df_all.iloc[:n_train]\n",
    "val_df   = df_all.iloc[n_train:n_train + n_val]\n",
    "test_df  = df_all.iloc[n_train + n_val:]\n",
    "\n",
    "# â”€â”€â”€ Guardar resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "train_df.to_excel(\"train_data_final_30_buses.xlsx\", index=False)\n",
    "val_df.to_excel(\"val_data_final_30_buses.xlsx\", index=False)\n",
    "test_df.to_excel(\"test_data_final_30_buses.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Datasets generados y divididos correctamente:\")\n",
    "print(f\"  Train â†’ {len(train_df)} muestras\")\n",
    "print(f\"  Val   â†’ {len(val_df)} muestras\")\n",
    "print(f\"  Test  â†’ {len(test_df)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95562b",
   "metadata": {},
   "source": [
    "## Test Case 118 Buses - Panda Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52e9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generadas: 5000/500000\n",
      "âœ… Datasets generados y divididos correctamente:\n",
      "  Train â†’ 21000 muestras\n",
      "  Val   â†’ 4500 muestras\n",
      "  Test  â†’ 4500 muestras\n"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks as nw\n",
    "import pandapower.topology as top\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy, random\n",
    "\n",
    "# ConfiguraciÃ³n inicial\n",
    "net_base = nw.case118()\n",
    "orig_p, orig_q = net_base.load.p_mw.copy(), net_base.load.q_mvar.copy()\n",
    "VAR_RANGE = 0.4\n",
    "\n",
    "# Funciones necesarias\n",
    "def is_connected(net):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return nx.is_connected(G)\n",
    "\n",
    "def eligible_nodes(net, min_degree):\n",
    "    G = top.create_nxgraph(net)\n",
    "    return [node for node, deg in G.degree if deg > min_degree]\n",
    "\n",
    "def lines_connected_to_node(net, node):\n",
    "    return net.line.index[(net.line.from_bus == node) | (net.line.to_bus == node)].tolist()\n",
    "\n",
    "def generate_sample(net, augment=True, max_attempts=20):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts and augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        k = random.choice([1, 2, 3])\n",
    "        eligible = eligible_nodes(net_trial, k)\n",
    "\n",
    "        if not eligible:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        node_selected = random.choice(eligible)\n",
    "        candidate_lines = lines_connected_to_node(net_trial, node_selected)\n",
    "\n",
    "        if len(candidate_lines) < k:\n",
    "            attempts += 1\n",
    "            continue\n",
    "\n",
    "        lines_off = random.sample(candidate_lines, k)\n",
    "        net_trial.line.loc[lines_off, 'in_service'] = False\n",
    "\n",
    "        if is_connected(net_trial):\n",
    "            try:\n",
    "                pp.runpp(net_trial)\n",
    "                return net_trial, lines_off\n",
    "            except pp.LoadflowNotConverged:\n",
    "                pass\n",
    "        attempts += 1\n",
    "\n",
    "    if not augment:\n",
    "        net_trial = copy.deepcopy(net)\n",
    "        pp.runpp(net_trial)\n",
    "        return net_trial, []\n",
    "\n",
    "    return None, []\n",
    "\n",
    "# Generador de registros\n",
    "def build_records(net, n_samples, augment):\n",
    "    records = []\n",
    "    sample_count = 0\n",
    "    while sample_count < n_samples:\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        net_copy.load['p_mw'] = orig_p * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_p)))\n",
    "        net_copy.load['q_mvar'] = orig_q * (1 + np.random.uniform(-VAR_RANGE, VAR_RANGE, len(orig_q)))\n",
    "\n",
    "        net_var, lines_off = generate_sample(net_copy, augment)\n",
    "\n",
    "        if net_var is None:\n",
    "            continue\n",
    "\n",
    "        Z_vector = np.ones(net.bus.shape[0], dtype=int)\n",
    "        for idx in lines_off:\n",
    "            Z_vector[net_var.line.at[idx, 'from_bus']] = 0\n",
    "            Z_vector[net_var.line.at[idx, 'to_bus']] = 0\n",
    "\n",
    "        rec = {\n",
    "            \"Sample\": f\"Data {sample_count+1}\",\n",
    "            \"Label\": \"FAIL\" if lines_off else \"OK\",\n",
    "            \"Edges_Out_List\": [f\"{net.line.at[idx, 'from_bus']}-{net.line.at[idx, 'to_bus']}\" for idx in lines_off],\n",
    "            \"Branch_Edge_Index\": [[], []],\n",
    "            \"Branch_G\": [], \"Branch_B\": [], \"Branch_Type\": [],\n",
    "            \"Z_vector\": Z_vector.tolist()\n",
    "        }\n",
    "\n",
    "        for _, ln in net_var.line[net_var.line.in_service].iterrows():\n",
    "            u, v = int(ln.from_bus), int(ln.to_bus)\n",
    "            z = complex(ln.r_ohm_per_km * ln.length_km, ln.x_ohm_per_km * ln.length_km)\n",
    "            y = 1/z\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(0)\n",
    "\n",
    "        for _, tr in net_var.trafo[net_var.trafo.in_service].iterrows():\n",
    "            u, v = int(tr.hv_bus), int(tr.lv_bus)\n",
    "            r_pu = tr.vkr_percent / 100.0\n",
    "            vk = tr.vk_percent / 100.0\n",
    "            x_pu = np.sqrt(max(vk*vk - r_pu*r_pu, 0.0))\n",
    "            y = 1 / complex(r_pu, x_pu)\n",
    "            rec[\"Branch_Edge_Index\"][0].append(u)\n",
    "            rec[\"Branch_Edge_Index\"][1].append(v)\n",
    "            rec[\"Branch_G\"].append(y.real)\n",
    "            rec[\"Branch_B\"].append(y.imag)\n",
    "            rec[\"Branch_Type\"].append(1)\n",
    "\n",
    "        for bus in net.bus.index:\n",
    "            p_load = net_var.res_load.p_mw[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            q_load = net_var.res_load.q_mvar[net_var.load.bus == bus].sum() if bus in net_var.load.bus.values else 0\n",
    "            ntype = \"PQ\" if bus in net_var.load.bus.values else (\"Slack\" if net_var.bus.at[bus, 'type']==3 else \"PV\")\n",
    "            rec[f\"P_{bus} ({ntype})\"], rec[f\"Q_{bus} ({ntype})\"] = p_load, q_load\n",
    "            rec[f\"V_{bus}\"] = net_var.res_bus.vm_pu.at[bus]\n",
    "            rec[f\"d_{bus}\"] = net_var.res_bus.va_degree.at[bus]\n",
    "            rec[f\"Z_{bus}\"] = int(Z_vector[bus])\n",
    "\n",
    "        records.append(rec)\n",
    "        sample_count += 1\n",
    "        print(f\"Generadas: {sample_count}/{n_samples}\", end='\\r')\n",
    "\n",
    "    return records\n",
    "\n",
    "# â”€â”€â”€ GeneraciÃ³n y mezcla total â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_records = (\n",
    "    build_records(net_base, 10000, augment=False) +\n",
    "    build_records(net_base, 5000, augment=True) +\n",
    "    build_records(net_base, 10000, augment=True) +\n",
    "    build_records(net_base, 5000, augment=False)\n",
    ")\n",
    "\n",
    "df_all = pd.DataFrame(all_records).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# â”€â”€â”€ Split 70% train / 15% val / 15% test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_total = len(df_all)\n",
    "n_train = int(0.70 * n_total)\n",
    "n_val   = int(0.15 * n_total)\n",
    "n_test  = n_total - n_train - n_val\n",
    "\n",
    "train_df = df_all.iloc[:n_train]\n",
    "val_df   = df_all.iloc[n_train:n_train + n_val]\n",
    "test_df  = df_all.iloc[n_train + n_val:]\n",
    "\n",
    "# â”€â”€â”€ Guardar resultados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "train_df.to_excel(\"train_data_final_118_buses.xlsx\", index=False)\n",
    "val_df.to_excel(\"val_data_final_118_buses.xlsx\", index=False)\n",
    "test_df.to_excel(\"test_data_final_118_buses.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Datasets generados y divididos correctamente:\")\n",
    "print(f\"  Train â†’ {len(train_df)} muestras\")\n",
    "print(f\"  Val   â†’ {len(val_df)} muestras\")\n",
    "print(f\"  Test  â†’ {len(test_df)} muestras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
